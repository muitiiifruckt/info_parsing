from playwright.sync_api import sync_playwright
import time
from bs4 import BeautifulSoup
from dataclasses import dataclass
from typing import List, Optional
from datetime import date, timedelta

# –°–ø–∏—Å–æ–∫ –∫–æ–º–ø–∞–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞
COMPANIES = ['–ì–∞–∑–ø—Ä–æ–º', '–°–±–µ—Ä–±–∞–Ω–∫', '–õ—É–∫–æ–π–ª']

@dataclass
class NewsItem:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –Ω–æ–≤–æ—Å—Ç–∏"""
    time: str
    title: str
    link: str
    company: str
    has_image: bool = False

class NewsParser:
    def __init__(self):
        self.news_list: List[NewsItem] = []
        
    def parse_news(self, html_content: str, company: str, page=None) -> List[NewsItem]:
        """–ü–∞—Ä—Å–∏—Ç HTML –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏"""
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞
        news_items = soup.find('div', class_='sPageResult')
        news_items = news_items.find_all("div",recursive =False)
        for item in news_items:
            try:
                # –î–∞—Ç–∞
                time_elem = item.find('time')
                news_time = time_elem.text.strip() if time_elem else None

                # –î–ª—è –±–ª–æ–∫–∞ —Å —Ñ–æ—Ç–æ –∏—â–µ–º –≤–Ω—É—Ç—Ä–∏ .title
                if 'sPageResult__photo' in item.get('class', []):
                    title_div = item.find('div', class_='title')
                    links = title_div.find_all('a') if title_div else []
                else:
                    links = item.find_all('a')

                if len(links) > 1:
                    news_link = links[1].get('href', '')
                    news_title = links[1].text.strip()
                    if news_link.startswith('/'):
                        news_link = f"https://www.interfax.ru{news_link}"
                else:
                    news_link = None
                    news_title = None

                print(f"–î–∞—Ç–∞: {news_time}")
                print(f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {news_title}")
                print(f"–°—Å—ã–ª–∫–∞: {news_link}")
                record = self.get_article_text(page, news_link) if page and news_link else None
                print(f"–°—Ç–∞—Ç—å—è - {record}")
                print('-' * 40)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                has_image = bool(item.find('img'))
                
                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –Ω–æ–≤–æ—Å—Ç–∏
                news_item = NewsItem(
                    time=news_time,
                    title=news_title,
                    link=news_link,
                    company=company,
                    has_image=has_image
                )
                
                self.news_list.append(news_item)
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–æ–≤–æ—Å—Ç–∏: {str(e)}")
                continue
                
        return self.news_list

    def get_article_text(self, page, url):
        page.goto(url)
        page.wait_for_load_state('networkidle')
        html = page.content()
        soup = BeautifulSoup(html, 'html.parser')
        paragraphs = soup.find_all('p')
        article_text = '\n'.join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))
        return article_text
    
    def print_news(self):
        """–í—ã–≤–æ–¥–∏—Ç –Ω–æ–≤–æ—Å—Ç–∏ –≤ –∫–æ–Ω—Å–æ–ª—å"""
        print("\n–ù–∞–π–¥–µ–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏:")
        print("-" * 80)
        
        for news in self.news_list:
            print(f"–ö–æ–º–ø–∞–Ω–∏—è: {news.company}")
            print(f"–í—Ä–µ–º—è: {news.time}")
            print(f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {news.title}")
            print(f"–°—Å—ã–ª–∫–∞: {news.link}")
            if news.has_image:
                print("üì∑ –ù–æ–≤–æ—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
            print("-" * 80)

def main():
    with sync_playwright() as p:
        # –ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞ –≤ –≤–∏–¥–∏–º–æ–º —Ä–µ–∂–∏–º–µ
        browser = p.chromium.launch(headless=False)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context = browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        )
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        page = context.new_page()
        
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
            parser = NewsParser()
            
            # –î–ª—è –∫–∞–∂–¥–æ–π –∫–æ–º–ø–∞–Ω–∏–∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            for company in COMPANIES:
                print(f"\n–ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –æ –∫–æ–º–ø–∞–Ω–∏–∏: {company}")
                
                # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞
                page.goto("https://www.interfax.ru/search/")
                time.sleep(1)
                
                # –ù–∞—Ö–æ–¥–∏–º —Ñ–æ—Ä–º—É –ø–æ–∏—Å–∫–∞ –∏ –≤–≤–æ–¥–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏
                search_form = page.locator('.sPageForm')
                search_input = page.locator('input[name="phrase"]')
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä –¥–ª—è –ø–æ–ª—è –≤–≤–æ–¥–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ—Ä–º–µ –ø–æ–∏—Å–∫–∞
                search_input = page.locator('main input[name="phrase"]')
                
                search_input.fill(company)
                # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –¥–∞—Ç—É "20.06.2024" –≤ –ø–æ–ª–µ —Å id="from"
                offset = date.today() - timedelta(days=1)
                date_str = offset.strftime('%d.%m.%Y')
                page.fill('input#from', date_str)
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º—É
                search_form.evaluate('form => form.submit()')
                time.sleep(2)  # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                
                # –ü–æ–ª—É—á–∞–µ–º HTML –∫–æ–Ω—Ç–µ–Ω—Ç
                html_content = page.content()
                
                # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                parser.parse_news(html_content, company, page=page)
                
                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(1)
            
            # –í—ã–≤–æ–¥–∏–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            parser.print_news()
            
            # –ñ–¥–µ–º, –ø–æ–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–∫—Ä–æ–µ—Ç –±—Ä–∞—É–∑–µ—Ä
            input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è –±—Ä–∞—É–∑–µ—Ä–∞...")
            
        finally:
            browser.close()

if __name__ == '__main__':
    main()
